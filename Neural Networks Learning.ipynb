{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " '__globals__': [],\n",
       " '__header__': b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Created on: Sun Oct 16 13:09:09 2011',\n",
       " '__version__': '1.0',\n",
       " 'y': array([[10],\n",
       "        [10],\n",
       "        [10],\n",
       "        ...,\n",
       "        [ 9],\n",
       "        [ 9],\n",
       "        [ 9]], dtype=uint8)}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat \n",
    "\n",
    "\n",
    "data = loadmat('ex4data1.mat')\n",
    "data # Dictionary object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'X', 'y'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 400)\n",
      "(5000, 1)\n"
     ]
    }
   ],
   "source": [
    "X = data['X'] # Converts X to numpy ndarray\n",
    "y = data['y'] # Converts y to numpy ndarray\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 401)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding column of ones to data matrix X\n",
    "X = np.c_[np.ones((m,1)), X]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'Theta1', 'Theta2'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading weights\n",
    "weights = loadmat('ex4weights.mat')\n",
    "weights.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta1 :  (25, 401)\n",
      "theta2 :  (10, 26)\n",
      "nn_params :  (10285,)\n"
     ]
    }
   ],
   "source": [
    "theta1, theta2 = weights['Theta1'], weights['Theta2']\n",
    "print('theta1 : ', theta1.shape)\n",
    "print('theta2 : ', theta2.shape)\n",
    "# Unrolling theta1 and theta2 vector\n",
    "nn_params = np.r_[theta1.ravel(), theta2.ravel()]\n",
    "print('nn_params : ', nn_params.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In nnCostFunction the formal parameter nn_params is always the array of unrolled weights that’s passed to it as an argument from the calling function (which is sometimes ex4 and sometimes fmincg). In ex4 the actual argument nn_params is the unrolled vector from the Theta weights loaded from the ‘ex4weights.mat’ file, and initial_nn_params is the unrolled vector from the Theta weights initialized by randInitializeWeights.\n",
    "\n",
    "ex4 calls nnCostFunction with nn_params directly a few times to check the forward propagation calculations, and calls fmincg with initial_nn_params to kick off its version of gradient descent. fmincg then calls nnCostFunction indirectly through the “short hand” costFunction to compute the cost and gradients and then fmincg updates the weights and repeats the optimization process until either there’s convergence or else the maximum number of iterations is reached.\n",
    "\n",
    "The optimization engine fmincg we use is a general purpose function and doesn’t know anything about neural networks. It just minimizes a cost based on an array of (unrolled) parameters and their corresponding gradients. It passes those parameters to nnCostFunction which does know about neural networks and reshapes the general parameter list back into Θ matrices to compute the cost and gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks - Feed Forward and Back Prop\n",
    "\n",
    "Input layer size = 400 (20 x 20)\n",
    "\n",
    "Hidden layer size = 25\n",
    "\n",
    "Number of labels = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sigmoid function\n",
    "def sigmoid(z):\n",
    "    return (1 / (1 + np.exp(-z))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid derivative\n",
    "def sigmoid_derivative(z):\n",
    "    s = sigmoid(z)\n",
    "    return (s * (1 - s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnCostFunction(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, lambdaa):\n",
    "    \n",
    "    # When comparing with octave code, Note that Python uses indexing from 0\n",
    "    # + 1 as we added colum of ones previously\n",
    "    theta1 = nn_params[0 : (hidden_layer_size * (input_layer_size + 1))].reshape(hidden_layer_size, input_layer_size + 1)\n",
    "    # theta1 is rolled into a matrix of shape (25, 401) containg 10025 elements\n",
    "    \n",
    "    theta2 = nn_params[(hidden_layer_size * (input_layer_size + 1)) : ].reshape(num_labels, hidden_layer_size + 1)\n",
    "    # theta2 is rolled into a matrix of shape (10, 26) containg 260 elements\n",
    "    \n",
    "    # PART - 1 FORWARD PROP AND COST\n",
    "    a1 = X\n",
    "    \n",
    "    # layer 1 to layer 2\n",
    "    z2 = np.dot(a1, theta1.T) # (5000, 401) * (25, 401).T\n",
    "    a2 = sigmoid(z2)\n",
    "    \n",
    "    # layer 2 to layer 3\n",
    "    a2 = np.c_[np.ones((m,1)), a2] # (5000,1) column-wise concatenation (5000, 25) = (5000, 26)\n",
    "    z3 = np.dot(a2, theta2.T) # (5000,10)\n",
    "    a3 = sigmoid(z3)\n",
    "    \n",
    "    # Converting 'y' vector to matrix 'y_mat'\n",
    "    #y_mat = pd.get_dummies(classes.ravel()).as_matrix()\n",
    "    \n",
    "    # Regularized cost\n",
    "    reg_term = np.sum(np.sum(theta1[:, 1:] ** 2)) + np.sum(np.sum(theta2[:, 1:] ** 2)) \n",
    "    J = (-1/m) * np.sum(y * np.log(a3) + (1 - y) * np.log(1 - a3)) + (lambdaa/(2*m)) * reg_term\n",
    "    \n",
    "    # PART - 2 BACK PROP TO COMPUTE THE GRADIENT Theta1_grad and Theta2_grad\n",
    "    tridelta1 = 0\n",
    "    tridelta2 = 0\n",
    "    \n",
    "    # Error for output layer is output - predicted output\n",
    "    d3 = a3 - y # (5000,10)\n",
    "    \n",
    "    # Error for hidden layer; from the formula used in lectures\n",
    "    d2 = np.dot(d3, theta2[:, 1:]) * sigmoid_derivative(z2) # (5000, 10) * (10, 25)\n",
    "    \n",
    "    tridelta1 = tridelta1 + np.dot(d2.T, a1) # (25,401) = theta1.shape\n",
    "    tridelta2 = tridelta2 + np.dot(d3.T, a2) # (10,26) = theta2.shape\n",
    "    \n",
    "    # Regularized gradient\n",
    "    # Set first column of theta1 and theta2 to zero ie; ignore the bias term\n",
    "    Theta1 = np.c_[np.zeros((theta1.shape[0], 1)), theta1[:, 1:]]\n",
    "    Theta2 = np.c_[np.zeros((theta2.shape[0], 1)), theta2[:, 1:]]\n",
    "    \n",
    "    theta1_grad = (1/m) * (tridelta1 + lambdaa * theta1)\n",
    "    theta2_grad = (1/m) * (tridelta2 + lambdaa * theta2)\n",
    "    \n",
    "    return (J, theta1_grad, theta2_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're also going to need to one-hot encode our labels. One-hot encoding turns a class label n (out of k classes) into a vector of length k where index n is \"hot\" (1) while the rest are zero. Scikit-learn has a built in utility we can use for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Returns an array; would return sparse matrix if sparse = True\n",
    "encoder = OneHotEncoder(sparse = False)\n",
    "\n",
    "y_OneHot = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.38376985909092365,\n",
       " array([[ 5.73587986e-05, -2.11248326e-12,  4.38829369e-13, ...,\n",
       "          7.09042553e-09,  1.84706139e-09,  5.60928898e-13],\n",
       "        [ 7.42035851e-05,  1.53233736e-12, -1.95174738e-12, ...,\n",
       "          2.10747891e-08, -8.61281252e-11,  7.08845709e-13],\n",
       "        [-1.69362396e-04, -1.75530893e-12,  1.63207553e-12, ...,\n",
       "          4.63501184e-08,  9.48509834e-10, -1.50133620e-12],\n",
       "        ...,\n",
       "        [ 2.94128026e-05, -1.77854412e-12, -1.96393620e-12, ...,\n",
       "         -9.34100149e-09,  1.29689159e-09,  1.80499812e-12],\n",
       "        [ 1.50102796e-04,  6.10356747e-14,  5.12122016e-13, ...,\n",
       "          3.33797620e-07, -3.66032512e-08,  7.67523996e-13],\n",
       "        [-1.33561977e-04,  1.77175372e-12, -1.31503028e-13, ...,\n",
       "          4.69418663e-09,  2.83929031e-09,  1.75890906e-12]]),\n",
       " array([[ 4.76536940e-04,  5.08457277e-04,  7.84221985e-05,\n",
       "          1.01449847e-03,  5.20245821e-04,  9.39490340e-04,\n",
       "         -4.65577532e-05, -4.26660299e-04, -8.07731636e-04,\n",
       "         -7.71028631e-06,  4.82754639e-04, -3.02397952e-04,\n",
       "          7.90088927e-04, -3.82712024e-04, -4.20832378e-04,\n",
       "         -5.97441420e-04,  1.54063425e-04,  6.46695974e-04,\n",
       "         -3.11351924e-04, -2.98178905e-05,  1.47912126e-04,\n",
       "          3.83904184e-04,  2.20175369e-04,  9.45488998e-04,\n",
       "          3.63474749e-04,  6.14286350e-04],\n",
       "        [ 2.41058977e-04, -2.07079702e-04,  4.82145154e-04,\n",
       "         -7.37421526e-04,  3.25075995e-04, -6.29785853e-05,\n",
       "          9.77659467e-05, -4.80023288e-04,  6.50702097e-04,\n",
       "          3.85072803e-04,  8.56149305e-04,  1.18942678e-03,\n",
       "          8.86750833e-04, -6.61457248e-04, -1.70082512e-04,\n",
       "         -7.06697773e-04,  1.03546843e-03,  3.20113371e-04,\n",
       "          1.01251278e-05,  7.95162890e-04,  4.95533776e-04,\n",
       "         -4.41076514e-04, -1.20050380e-04, -9.32594866e-04,\n",
       "          9.54416790e-04, -6.12445890e-04],\n",
       "        [ 2.58100973e-04,  7.39748359e-04, -8.54078171e-04,\n",
       "          1.21538179e-03,  3.43516582e-05, -6.35489943e-04,\n",
       "         -3.86540641e-04,  6.05590021e-04,  3.04387056e-04,\n",
       "          2.97781071e-04, -3.17903164e-04,  9.96792335e-04,\n",
       "         -2.38474319e-04, -1.96746969e-04, -9.92995660e-04,\n",
       "          1.00702114e-03,  6.66418175e-04, -4.47991227e-04,\n",
       "          4.48706234e-04,  7.56442884e-04,  7.36509906e-04,\n",
       "          1.26354187e-04, -8.44266246e-05,  4.86839391e-04,\n",
       "         -3.45752234e-04,  2.26506559e-04],\n",
       "        [ 3.05643889e-04, -1.56655882e-04, -2.08832801e-04,\n",
       "          8.55995929e-05, -7.44929941e-04,  9.85540352e-05,\n",
       "          7.70308460e-04, -1.78048274e-04, -3.92765917e-04,\n",
       "          1.34025092e-03, -6.18385060e-04, -1.26624632e-04,\n",
       "          4.07491955e-04,  1.06907874e-03, -3.54899713e-04,\n",
       "          2.03999229e-04,  2.66549481e-04,  6.38547145e-04,\n",
       "         -4.63637352e-05,  8.09523297e-05, -7.21630429e-04,\n",
       "         -4.89567948e-04,  1.09787517e-03,  4.89620376e-05,\n",
       "          7.96598255e-04,  5.87561760e-04],\n",
       "        [ 1.33114981e-04,  8.13858471e-04, -8.77172888e-04,\n",
       "         -8.12358456e-04, -1.32081959e-04,  8.36925903e-04,\n",
       "          9.76198717e-05, -7.59950990e-04,  5.85576093e-04,\n",
       "          1.34960262e-05, -1.29684701e-04, -3.96534646e-04,\n",
       "         -5.20556461e-04,  5.81267908e-05,  6.01839449e-04,\n",
       "          6.08221385e-05,  2.38743171e-04, -4.70931475e-04,\n",
       "         -6.04744603e-04, -1.31210819e-03,  8.74561699e-04,\n",
       "          9.83221571e-04,  1.20304657e-03,  6.75118092e-04,\n",
       "          2.60772582e-04, -1.04982393e-03],\n",
       "        [ 3.87881719e-04, -1.46002649e-04,  3.68153057e-04,\n",
       "         -3.39891774e-05,  1.76722049e-04, -2.02917284e-04,\n",
       "         -1.54263203e-04,  1.07250346e-03, -9.00098859e-04,\n",
       "          8.54790420e-04,  7.48826375e-04, -4.15432558e-04,\n",
       "         -3.01180565e-04, -8.22667611e-04,  4.70021315e-04,\n",
       "          2.18240892e-04, -3.84385245e-04,  5.77798486e-04,\n",
       "          9.26531885e-04, -9.02697533e-05,  1.60005086e-04,\n",
       "          9.28067047e-04, -6.92258510e-05,  4.94102372e-04,\n",
       "          6.77113955e-04,  3.35116006e-04],\n",
       "        [ 2.54005501e-04, -4.47702238e-04,  6.12228395e-04,\n",
       "          8.09978930e-04,  5.99587903e-04,  9.76800083e-04,\n",
       "          9.54414446e-04,  5.46073721e-04,  3.43089957e-04,\n",
       "          2.83167019e-04, -5.69601529e-04,  6.55928716e-04,\n",
       "         -1.85989878e-04,  3.22093309e-04, -3.37814348e-04,\n",
       "         -8.21194134e-04, -1.75161615e-04, -1.37941081e-04,\n",
       "          5.23477526e-04,  2.93397342e-05, -5.70893050e-04,\n",
       "          4.84192710e-04,  3.14562157e-04,  2.39265997e-05,\n",
       "         -6.39317958e-04, -6.47826038e-04],\n",
       "        [ 3.93883661e-04,  3.01192446e-04,  1.32223008e-03,\n",
       "         -1.06519551e-04,  6.19101861e-05,  3.79958938e-04,\n",
       "         -5.44265279e-04,  9.19222163e-04,  7.75382974e-04,\n",
       "         -3.55306468e-04,  6.77490309e-04, -4.59102576e-04,\n",
       "         -8.01324322e-04,  8.28539738e-04,  8.49729917e-04,\n",
       "          1.34916636e-04,  9.26222561e-04,  1.21976602e-03,\n",
       "         -2.52690513e-04,  1.10792560e-03,  5.17456345e-04,\n",
       "         -7.23960814e-04,  4.91877062e-04,  1.81483109e-04,\n",
       "         -2.34067843e-04,  8.57546470e-04],\n",
       "        [ 7.16345983e-04,  3.83188736e-05, -3.01062889e-04,\n",
       "          5.75314836e-04,  1.79068287e-03,  1.02102420e-04,\n",
       "          1.23450744e-03, -1.22910746e-04,  5.05050507e-04,\n",
       "         -6.25902138e-04,  2.03242436e-04,  7.57781546e-05,\n",
       "          7.84540569e-04,  3.58292110e-04,  9.32739214e-04,\n",
       "          1.23883207e-03,  7.22085802e-06,  5.55589828e-04,\n",
       "         -7.09031875e-05, -1.09975753e-04,  9.20669710e-04,\n",
       "          9.36710281e-05, -4.13685849e-04,  4.56012778e-04,\n",
       "          8.53649429e-04,  9.30689893e-04],\n",
       "        [ 1.55376260e-04,  5.52732590e-04,  5.06184355e-04,\n",
       "         -3.33703789e-04, -1.84675052e-04,  9.11864246e-05,\n",
       "         -2.62038154e-04,  2.73183780e-04,  2.72893709e-04,\n",
       "         -5.18589882e-05,  5.13911610e-04,  7.19346509e-04,\n",
       "          1.08738325e-03,  8.58375367e-04,  6.88444591e-04,\n",
       "          3.58726188e-04, -3.85946077e-04, -4.83106746e-04,\n",
       "          7.60151721e-04, -2.08791493e-04, -7.19242152e-04,\n",
       "          5.54323061e-04, -3.66957463e-04,  4.70513145e-05,\n",
       "         -5.01718610e-04,  5.07825789e-04]]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnCostFunction(nn_params, 400, 25, 10, X, y_OneHot, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
